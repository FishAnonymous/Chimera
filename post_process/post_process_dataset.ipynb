{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5a5ee670",
   "metadata": {},
   "source": [
    "## Membership Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e514896c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import json5\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "company = \"finance_corporation\"\n",
    "# company = \"tech_company\"\n",
    "# company = \"medical_institution\"\n",
    "folder_path = '/data2/visitor/ASE25/Chimera-Dataset/Finance-Company/generated_members'\n",
    "# folder_path = '/data2/visitor/ASE25/Chimera-Dataset/Tech-Company/generated_members'\n",
    "# folder_path = '/data2/visitor/ASE25/Chimera-Dataset/Medical-Institution/generated_members'\n",
    "\n",
    "output_csv = f'{company}.csv'\n",
    "\n",
    "data_list = []\n",
    "\n",
    "for filename in os.listdir(folder_path):\n",
    "    if filename.endswith('.jsonc'):\n",
    "        file_path = os.path.join(folder_path, filename)\n",
    "        with open(file_path, 'r', encoding='utf-8') as f:\n",
    "            try:\n",
    "                content = json5.load(f)\n",
    "                data = {\n",
    "                    \"name\": content.get(\"name\"),\n",
    "                    \"id\": content.get(\"id\"),\n",
    "                    \"role\": content.get(\"role\"),\n",
    "                    \"ip\": content.get(\"ip\"),\n",
    "                    \"email\": content.get(\"email\"),\n",
    "                    \"container_id\": content.get(\"container_id\"),\n",
    "                    \"mbti\": content.get(\"mbti\"),\n",
    "                    \"interests\": content.get(\"interests\"),\n",
    "                    \"personality\": content.get(\"personality\")\n",
    "                }\n",
    "                data_list.append(data)\n",
    "            except Exception as e:\n",
    "                print(f\"Error loading {filename}: {e}\")\n",
    "\n",
    "# 用pandas生成DataFrame\n",
    "df = pd.DataFrame(data_list)\n",
    "\n",
    "# save with column names\n",
    "df.to_csv(output_csv, index=True, header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7696937",
   "metadata": {},
   "source": [
    "## Email Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "20020cc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import pandas as pd\n",
    "import json\n",
    "import ast\n",
    "\n",
    "# read four dirs email.csv\n",
    "weeks = range(1, 5)\n",
    "week_dates = [5, 5, 5, 5]\n",
    "week_pointer = 0\n",
    "\n",
    "scenario = \"Tech-Company\"\n",
    "company_type = \"tech\"\n",
    "\n",
    "# Reading\n",
    "root_dir = f'/data2/visitor/ASE25/Chimera-Dataset/'\n",
    "\n",
    "# concat all the email.csv\n",
    "email_csvs = pd.DataFrame()\n",
    "\n",
    "for week in weeks:\n",
    "    weekly_dir = os.path.join(root_dir, scenario, f'week{week}-gemini-{company_type}')\n",
    "    weekly_email_log_path = os.path.join(weekly_dir, \"execution_logs\", 'email.csv')\n",
    "    \n",
    "    df = pd.read_csv(weekly_email_log_path, encoding='utf-8')\n",
    "\n",
    "    # Concatenate all DataFrames\n",
    "    email_csvs = pd.concat([email_csvs, df], ignore_index=True)\n",
    "\n",
    "# update a new column \"sim_timestamp\" with date and the time. The date start from starting_date and add 1 day when the next cell(time) is smaller than the previous cell\n",
    "starting_date = \"2025-05-01\"\n",
    "# email_csvs['sim_timestamp'] = pd.to_datetime(starting_date) + pd.to_timedelta(email_csvs.index, unit='d')\n",
    "\n",
    "#### settle the sim timestamp with proper date ####\n",
    "date_counter = 1\n",
    "for i in range(len(email_csvs)):\n",
    "    sim_time = pd.to_datetime(email_csvs.loc[i, 'sim_timestamp'], format='%H:%M:%S')\n",
    "    \n",
    "    if i == 0:\n",
    "        sim_date = starting_date\n",
    "    else:\n",
    "        prev_time = pd.to_datetime(email_csvs.loc[i-1, 'sim_timestamp'], format='%H:%M:%S')\n",
    "        if (sim_time < prev_time) and ((prev_time - sim_time) > pd.Timedelta(hours=6)):\n",
    "            if date_counter == week_dates[week_pointer]:\n",
    "                # print(\"next week\")\n",
    "                add_date = 8 - week_dates[week_pointer]\n",
    "                week_pointer += 1\n",
    "                date_counter = 1\n",
    "            else:\n",
    "                date_counter += 1\n",
    "                add_date = 1\n",
    "            sim_date = (pd.to_datetime(sim_date) + pd.Timedelta(days=add_date)).strftime('%Y-%m-%d')\n",
    "            # print(f\"Date changed to {sim_date} at index {i}\")\n",
    "    email_csvs.loc[i, 'full_sim_timestamp'] = f\"{sim_date} {email_csvs.loc[i, 'sim_timestamp']}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7dd55d07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>email_from</th>\n",
       "      <th>real_timestamp</th>\n",
       "      <th>sim_timestamp</th>\n",
       "      <th>name</th>\n",
       "      <th>email_to</th>\n",
       "      <th>email_cc</th>\n",
       "      <th>subject</th>\n",
       "      <th>content</th>\n",
       "      <th>full_sim_timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>qtest-1</td>\n",
       "      <td>2025-05-15 15:04:55</td>\n",
       "      <td>08:00:10</td>\n",
       "      <td>Ethan Carter</td>\n",
       "      <td>LDES-1</td>\n",
       "      <td>['SDES-1', 'SDES-2']</td>\n",
       "      <td>GDD Review and Clarification Needed</td>\n",
       "      <td>Team,\\n\\nI've started my review of the current...</td>\n",
       "      <td>2025-05-01 08:00:10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sdes-1</td>\n",
       "      <td>2025-05-15 15:06:15</td>\n",
       "      <td>08:22:13</td>\n",
       "      <td>Rajan Patel</td>\n",
       "      <td>ldes-1</td>\n",
       "      <td>['prod-1']</td>\n",
       "      <td>Action Items: Combat, Economy, and Progression...</td>\n",
       "      <td>Team,\\n\\nFollowing up on our initial alignment...</td>\n",
       "      <td>2025-05-01 08:22:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>prod-1</td>\n",
       "      <td>2025-05-15 15:06:20</td>\n",
       "      <td>08:24:26</td>\n",
       "      <td>Olivia Rodriguez</td>\n",
       "      <td>sdes-1</td>\n",
       "      <td>[]</td>\n",
       "      <td>Re: Action Items: Combat, Economy, and Progres...</td>\n",
       "      <td>Hi Rajan,\\n\\nThanks for the detailed breakdown...</td>\n",
       "      <td>2025-05-01 08:24:26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sdes-1</td>\n",
       "      <td>2025-05-15 15:06:25</td>\n",
       "      <td>08:25:09</td>\n",
       "      <td>Rajan Patel</td>\n",
       "      <td>prod-1</td>\n",
       "      <td>[]</td>\n",
       "      <td>Re: Action Items: Combat, Economy, and Progres...</td>\n",
       "      <td>Hi Olivia,\\n\\nThanks for your feedback. I unde...</td>\n",
       "      <td>2025-05-01 08:25:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ldes-1</td>\n",
       "      <td>2025-05-15 15:06:42</td>\n",
       "      <td>08:28:52</td>\n",
       "      <td>Naomi Walker</td>\n",
       "      <td>sdes-1</td>\n",
       "      <td>[]</td>\n",
       "      <td>Re: Action Items: Combat, Economy, and Progres...</td>\n",
       "      <td>Rajan,\\n\\nThanks for the clear breakdown. Just...</td>\n",
       "      <td>2025-05-01 08:28:52</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  email_from       real_timestamp sim_timestamp              name email_to  \\\n",
       "0    qtest-1  2025-05-15 15:04:55      08:00:10      Ethan Carter   LDES-1   \n",
       "1     sdes-1  2025-05-15 15:06:15      08:22:13       Rajan Patel   ldes-1   \n",
       "2     prod-1  2025-05-15 15:06:20      08:24:26  Olivia Rodriguez   sdes-1   \n",
       "3     sdes-1  2025-05-15 15:06:25      08:25:09       Rajan Patel   prod-1   \n",
       "4     ldes-1  2025-05-15 15:06:42      08:28:52      Naomi Walker   sdes-1   \n",
       "\n",
       "               email_cc                                            subject  \\\n",
       "0  ['SDES-1', 'SDES-2']                GDD Review and Clarification Needed   \n",
       "1            ['prod-1']  Action Items: Combat, Economy, and Progression...   \n",
       "2                    []  Re: Action Items: Combat, Economy, and Progres...   \n",
       "3                    []  Re: Action Items: Combat, Economy, and Progres...   \n",
       "4                    []  Re: Action Items: Combat, Economy, and Progres...   \n",
       "\n",
       "                                             content   full_sim_timestamp  \n",
       "0  Team,\\n\\nI've started my review of the current...  2025-05-01 08:00:10  \n",
       "1  Team,\\n\\nFollowing up on our initial alignment...  2025-05-01 08:22:13  \n",
       "2  Hi Rajan,\\n\\nThanks for the detailed breakdown...  2025-05-01 08:24:26  \n",
       "3  Hi Olivia,\\n\\nThanks for your feedback. I unde...  2025-05-01 08:25:09  \n",
       "4  Rajan,\\n\\nThanks for the clear breakdown. Just...  2025-05-01 08:28:52  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "email_csvs.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "715cef4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "company_type = \"tech_company\"\n",
    "\n",
    "\n",
    "# Add the missing columns\n",
    "\n",
    "### 1. add id list with content from email_from insert next to the index\n",
    "email_csvs.insert(0, 'id', email_csvs['email_from'])\n",
    "\n",
    "id_role_map = {}\n",
    "id_list = []\n",
    "profile_list = []\n",
    "\n",
    "profile_output_dir = f\"experiment_output/gemini_{company_type}/generated_members\"\n",
    "for file in os.listdir(profile_output_dir):\n",
    "    if file.endswith(\".jsonc\"):\n",
    "        member_profile_path = os.path.join(profile_output_dir, file)\n",
    "        with open(member_profile_path, 'r') as f:\n",
    "            member_profile = json.load(f)\n",
    "        id_role_map[member_profile['id']] = member_profile['role'] # add id-role map\n",
    "        id_list.append(member_profile['id'])\n",
    "        profile_list.append(member_profile) # add profile\n",
    "\n",
    "id_email_map = {profile['id']: profile['email'] for profile in profile_list}\n",
    "id_pc_map = {profile['id']: profile['container_id'] for profile in profile_list}\n",
    "\n",
    "### 2. replace email_from with the email\n",
    "email_csvs['email_from'] = email_csvs['email_from'].map(id_email_map)\n",
    "\n",
    "### 3. replace email_to with the email\n",
    "email_csvs['email_to'] = email_csvs['email_to'].map(id_email_map)\n",
    "# change the column name to \"to\"\n",
    "email_csvs.rename(columns={'email_to': 'to'}, inplace=True)\n",
    "\n",
    "### 4. replace email_cc list\n",
    "for i in range(len(email_csvs)):\n",
    "    if email_csvs.loc[i, 'email_cc'] == '[]':\n",
    "        email_cc_out = \"NaN\"\n",
    "    else:\n",
    "        email_cc_list = ast.literal_eval(email_csvs.loc[i, 'email_cc'])\n",
    "        email_cc_out_list = []\n",
    "        for email_des in email_cc_list:\n",
    "            # go through map id_email_map to find the email\n",
    "            # to lower case\n",
    "            email_des = email_des.lower()\n",
    "            email_cc_out_list.append(id_email_map.get(email_des, email_des))\n",
    "            email_cc_out = ', '.join(email_cc_out_list)\n",
    "    email_csvs.loc[i, 'email_cc'] = email_cc_out\n",
    "\n",
    "### 5. add new column named \"size\" to calculate the word count of the email_content\n",
    "content_idx = email_csvs.columns.get_loc('content')\n",
    "email_csvs.insert(content_idx+1, 'size', email_csvs['content'].apply(lambda x: len(x.split()) if isinstance(x, str) else 0))\n",
    "\n",
    "### 6. add new column named \"attachment\" with value of \"0\"\n",
    "email_csvs.insert(email_csvs.columns.get_loc('size') + 1, 'attachments', 0)\n",
    "\n",
    "### 7. add new column named \"pc\" with profile content of \"container_id\"\n",
    "email_csvs.insert(email_csvs.columns.get_loc('name') + 1, 'pc', email_csvs['id'].map(id_pc_map))\n",
    "\n",
    "### 8. add new column named \"bcc\"\n",
    "email_csvs.insert(email_csvs.columns.get_loc('email_cc') + 1, 'bcc', 'NaN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6167c9c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>email_from</th>\n",
       "      <th>real_timestamp</th>\n",
       "      <th>sim_timestamp</th>\n",
       "      <th>name</th>\n",
       "      <th>pc</th>\n",
       "      <th>to</th>\n",
       "      <th>email_cc</th>\n",
       "      <th>bcc</th>\n",
       "      <th>subject</th>\n",
       "      <th>content</th>\n",
       "      <th>size</th>\n",
       "      <th>attachments</th>\n",
       "      <th>full_sim_timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>qtest-1</td>\n",
       "      <td>qa-234987@corp.com</td>\n",
       "      <td>2025-05-15 15:04:55</td>\n",
       "      <td>08:00:10</td>\n",
       "      <td>Ethan Carter</td>\n",
       "      <td>7b8a9c0d1e2f</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sysdes-238759@corp.com, sysdes-981273@corp.com</td>\n",
       "      <td>NaN</td>\n",
       "      <td>GDD Review and Clarification Needed</td>\n",
       "      <td>Team,\\n\\nI've started my review of the current...</td>\n",
       "      <td>176</td>\n",
       "      <td>0</td>\n",
       "      <td>2025-05-01 08:00:10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sdes-1</td>\n",
       "      <td>sysdes-238759@corp.com</td>\n",
       "      <td>2025-05-15 15:06:15</td>\n",
       "      <td>08:22:13</td>\n",
       "      <td>Rajan Patel</td>\n",
       "      <td>9b5c6d7e82a3</td>\n",
       "      <td>gamedesign-195738@corp.com</td>\n",
       "      <td>produce-543210@corp.com</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Action Items: Combat, Economy, and Progression...</td>\n",
       "      <td>Team,\\n\\nFollowing up on our initial alignment...</td>\n",
       "      <td>233</td>\n",
       "      <td>0</td>\n",
       "      <td>2025-05-01 08:22:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>prod-1</td>\n",
       "      <td>produce-543210@corp.com</td>\n",
       "      <td>2025-05-15 15:06:20</td>\n",
       "      <td>08:24:26</td>\n",
       "      <td>Olivia Rodriguez</td>\n",
       "      <td>c3d2e1f0a9b8</td>\n",
       "      <td>sysdes-238759@corp.com</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Re: Action Items: Combat, Economy, and Progres...</td>\n",
       "      <td>Hi Rajan,\\n\\nThanks for the detailed breakdown...</td>\n",
       "      <td>177</td>\n",
       "      <td>0</td>\n",
       "      <td>2025-05-01 08:24:26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sdes-1</td>\n",
       "      <td>sysdes-238759@corp.com</td>\n",
       "      <td>2025-05-15 15:06:25</td>\n",
       "      <td>08:25:09</td>\n",
       "      <td>Rajan Patel</td>\n",
       "      <td>9b5c6d7e82a3</td>\n",
       "      <td>produce-543210@corp.com</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Re: Action Items: Combat, Economy, and Progres...</td>\n",
       "      <td>Hi Olivia,\\n\\nThanks for your feedback. I unde...</td>\n",
       "      <td>270</td>\n",
       "      <td>0</td>\n",
       "      <td>2025-05-01 08:25:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ldes-1</td>\n",
       "      <td>gamedesign-195738@corp.com</td>\n",
       "      <td>2025-05-15 15:06:42</td>\n",
       "      <td>08:28:52</td>\n",
       "      <td>Naomi Walker</td>\n",
       "      <td>f89a4b3c21d0</td>\n",
       "      <td>sysdes-238759@corp.com</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Re: Action Items: Combat, Economy, and Progres...</td>\n",
       "      <td>Rajan,\\n\\nThanks for the clear breakdown. Just...</td>\n",
       "      <td>186</td>\n",
       "      <td>0</td>\n",
       "      <td>2025-05-01 08:28:52</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                  email_from       real_timestamp sim_timestamp  \\\n",
       "0  qtest-1          qa-234987@corp.com  2025-05-15 15:04:55      08:00:10   \n",
       "1   sdes-1      sysdes-238759@corp.com  2025-05-15 15:06:15      08:22:13   \n",
       "2   prod-1     produce-543210@corp.com  2025-05-15 15:06:20      08:24:26   \n",
       "3   sdes-1      sysdes-238759@corp.com  2025-05-15 15:06:25      08:25:09   \n",
       "4   ldes-1  gamedesign-195738@corp.com  2025-05-15 15:06:42      08:28:52   \n",
       "\n",
       "               name            pc                          to  \\\n",
       "0      Ethan Carter  7b8a9c0d1e2f                         NaN   \n",
       "1       Rajan Patel  9b5c6d7e82a3  gamedesign-195738@corp.com   \n",
       "2  Olivia Rodriguez  c3d2e1f0a9b8      sysdes-238759@corp.com   \n",
       "3       Rajan Patel  9b5c6d7e82a3     produce-543210@corp.com   \n",
       "4      Naomi Walker  f89a4b3c21d0      sysdes-238759@corp.com   \n",
       "\n",
       "                                         email_cc  bcc  \\\n",
       "0  sysdes-238759@corp.com, sysdes-981273@corp.com  NaN   \n",
       "1                         produce-543210@corp.com  NaN   \n",
       "2                                             NaN  NaN   \n",
       "3                                             NaN  NaN   \n",
       "4                                             NaN  NaN   \n",
       "\n",
       "                                             subject  \\\n",
       "0                GDD Review and Clarification Needed   \n",
       "1  Action Items: Combat, Economy, and Progression...   \n",
       "2  Re: Action Items: Combat, Economy, and Progres...   \n",
       "3  Re: Action Items: Combat, Economy, and Progres...   \n",
       "4  Re: Action Items: Combat, Economy, and Progres...   \n",
       "\n",
       "                                             content  size  attachments  \\\n",
       "0  Team,\\n\\nI've started my review of the current...   176            0   \n",
       "1  Team,\\n\\nFollowing up on our initial alignment...   233            0   \n",
       "2  Hi Rajan,\\n\\nThanks for the detailed breakdown...   177            0   \n",
       "3  Hi Olivia,\\n\\nThanks for your feedback. I unde...   270            0   \n",
       "4  Rajan,\\n\\nThanks for the clear breakdown. Just...   186            0   \n",
       "\n",
       "    full_sim_timestamp  \n",
       "0  2025-05-01 08:00:10  \n",
       "1  2025-05-01 08:22:13  \n",
       "2  2025-05-01 08:24:26  \n",
       "3  2025-05-01 08:25:09  \n",
       "4  2025-05-01 08:28:52  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "email_csvs.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8121f6ce",
   "metadata": {},
   "source": [
    "### Format Fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "1193154f",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = f\"/data2/visitor/ASE25/Chimera/Final-Output/{scenario}/\"\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "sim_idx = email_csvs.columns.get_loc(\"sim_timestamp\")\n",
    "full_sim = email_csvs.pop(\"full_sim_timestamp\")\n",
    "email_csvs.insert(sim_idx + 1, \"full_sim_timestamp\", full_sim)\n",
    "\n",
    "# rename the column \"name\" to \"user\"\n",
    "email_csvs.rename(columns={'name': 'user'}, inplace=True)\n",
    "# rename the column \"full_sim_timestamp\" to \"time\"\n",
    "email_csvs.rename(columns={'full_sim_timestamp': 'date'}, inplace=True)\n",
    "# rename the column \"email_cc\" to \"cc\"\n",
    "email_csvs.rename(columns={'email_cc': 'cc'}, inplace=True)\n",
    "email_csvs.rename(columns={'email_from': 'from'}, inplace=True)\n",
    "\n",
    "# remove the column \"real_timestamp\" and \"sim_timestamp\"\n",
    "email_csvs.drop(columns=['real_timestamp', 'sim_timestamp'], inplace=True)\n",
    "\n",
    "# sorting by time\n",
    "email_csvs = email_csvs.sort_values(by='date', ascending=True).reset_index(drop=True)\n",
    "\n",
    "# save the email_csvs to csv\n",
    "email_csvs.to_csv(f'{output_dir}/{company_type}-email.csv', index=True, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "eba5d34c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>from</th>\n",
       "      <th>date</th>\n",
       "      <th>user</th>\n",
       "      <th>pc</th>\n",
       "      <th>to</th>\n",
       "      <th>cc</th>\n",
       "      <th>bcc</th>\n",
       "      <th>subject</th>\n",
       "      <th>content</th>\n",
       "      <th>size</th>\n",
       "      <th>attachments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>qtest-1</td>\n",
       "      <td>qa-234987@corp.com</td>\n",
       "      <td>2025-05-01 08:00:10</td>\n",
       "      <td>Ethan Carter</td>\n",
       "      <td>7b8a9c0d1e2f</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sysdes-238759@corp.com, sysdes-981273@corp.com</td>\n",
       "      <td>NaN</td>\n",
       "      <td>GDD Review and Clarification Needed</td>\n",
       "      <td>Team,\\n\\nI've started my review of the current...</td>\n",
       "      <td>176</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sdes-1</td>\n",
       "      <td>sysdes-238759@corp.com</td>\n",
       "      <td>2025-05-01 08:22:13</td>\n",
       "      <td>Rajan Patel</td>\n",
       "      <td>9b5c6d7e82a3</td>\n",
       "      <td>gamedesign-195738@corp.com</td>\n",
       "      <td>produce-543210@corp.com</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Action Items: Combat, Economy, and Progression...</td>\n",
       "      <td>Team,\\n\\nFollowing up on our initial alignment...</td>\n",
       "      <td>233</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>prod-1</td>\n",
       "      <td>produce-543210@corp.com</td>\n",
       "      <td>2025-05-01 08:24:26</td>\n",
       "      <td>Olivia Rodriguez</td>\n",
       "      <td>c3d2e1f0a9b8</td>\n",
       "      <td>sysdes-238759@corp.com</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Re: Action Items: Combat, Economy, and Progres...</td>\n",
       "      <td>Hi Rajan,\\n\\nThanks for the detailed breakdown...</td>\n",
       "      <td>177</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sdes-1</td>\n",
       "      <td>sysdes-238759@corp.com</td>\n",
       "      <td>2025-05-01 08:25:09</td>\n",
       "      <td>Rajan Patel</td>\n",
       "      <td>9b5c6d7e82a3</td>\n",
       "      <td>produce-543210@corp.com</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Re: Action Items: Combat, Economy, and Progres...</td>\n",
       "      <td>Hi Olivia,\\n\\nThanks for your feedback. I unde...</td>\n",
       "      <td>270</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ldes-1</td>\n",
       "      <td>gamedesign-195738@corp.com</td>\n",
       "      <td>2025-05-01 08:28:52</td>\n",
       "      <td>Naomi Walker</td>\n",
       "      <td>f89a4b3c21d0</td>\n",
       "      <td>sysdes-238759@corp.com</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Re: Action Items: Combat, Economy, and Progres...</td>\n",
       "      <td>Rajan,\\n\\nThanks for the clear breakdown. Just...</td>\n",
       "      <td>186</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                        from                 date              user  \\\n",
       "0  qtest-1          qa-234987@corp.com  2025-05-01 08:00:10      Ethan Carter   \n",
       "1   sdes-1      sysdes-238759@corp.com  2025-05-01 08:22:13       Rajan Patel   \n",
       "2   prod-1     produce-543210@corp.com  2025-05-01 08:24:26  Olivia Rodriguez   \n",
       "3   sdes-1      sysdes-238759@corp.com  2025-05-01 08:25:09       Rajan Patel   \n",
       "4   ldes-1  gamedesign-195738@corp.com  2025-05-01 08:28:52      Naomi Walker   \n",
       "\n",
       "             pc                          to  \\\n",
       "0  7b8a9c0d1e2f                         NaN   \n",
       "1  9b5c6d7e82a3  gamedesign-195738@corp.com   \n",
       "2  c3d2e1f0a9b8      sysdes-238759@corp.com   \n",
       "3  9b5c6d7e82a3     produce-543210@corp.com   \n",
       "4  f89a4b3c21d0      sysdes-238759@corp.com   \n",
       "\n",
       "                                               cc  bcc  \\\n",
       "0  sysdes-238759@corp.com, sysdes-981273@corp.com  NaN   \n",
       "1                         produce-543210@corp.com  NaN   \n",
       "2                                             NaN  NaN   \n",
       "3                                             NaN  NaN   \n",
       "4                                             NaN  NaN   \n",
       "\n",
       "                                             subject  \\\n",
       "0                GDD Review and Clarification Needed   \n",
       "1  Action Items: Combat, Economy, and Progression...   \n",
       "2  Re: Action Items: Combat, Economy, and Progres...   \n",
       "3  Re: Action Items: Combat, Economy, and Progres...   \n",
       "4  Re: Action Items: Combat, Economy, and Progres...   \n",
       "\n",
       "                                             content  size  attachments  \n",
       "0  Team,\\n\\nI've started my review of the current...   176            0  \n",
       "1  Team,\\n\\nFollowing up on our initial alignment...   233            0  \n",
       "2  Hi Rajan,\\n\\nThanks for the detailed breakdown...   177            0  \n",
       "3  Hi Olivia,\\n\\nThanks for your feedback. I unde...   270            0  \n",
       "4  Rajan,\\n\\nThanks for the clear breakdown. Just...   186            0  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "email_csvs.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ca37b9b",
   "metadata": {},
   "source": [
    "## Logon Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "473b806d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing /data2/visitor/ASE25/Chimera-Dataset/Tech-Company/week1-gemini-tech/execution_logs/logon.csv with 2855 rows\n",
      "Processing /data2/visitor/ASE25/Chimera-Dataset/Tech-Company/week2-gemini-tech/execution_logs/logon.csv with 3059 rows\n",
      "Processing /data2/visitor/ASE25/Chimera-Dataset/Tech-Company/week3-gemini-tech/execution_logs/logon.csv with 2805 rows\n",
      "Processing /data2/visitor/ASE25/Chimera-Dataset/Tech-Company/week4-gemini-tech/execution_logs/logon.csv with 3538 rows\n",
      "Total rows in logon_csvs: 12257\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "import random\n",
    "import pandas as pd\n",
    "\n",
    "# read four dirs logon.csv\n",
    "weeks = range(1, 5)\n",
    "week_dates = [5, 5, 5, 5]\n",
    "week_pointer = 0\n",
    "\n",
    "scenario = \"Tech-Company\"\n",
    "company_type = \"tech\"\n",
    "\n",
    "# Reading\n",
    "root_dir = f'/data2/visitor/ASE25/Chimera-Dataset/'\n",
    "\n",
    "# concat all the logon.csv\n",
    "logon_csvs = pd.DataFrame()\n",
    "\n",
    "#### load all data ####\n",
    "for week in weeks:\n",
    "    weekly_dir = os.path.join(root_dir, scenario, f'week{week}-gemini-{company_type}')\n",
    "    weekly_logon_log_path = os.path.join(weekly_dir, \"execution_logs\", 'logon.csv')\n",
    "\n",
    "    df = pd.read_csv(weekly_logon_log_path, encoding='utf-8')\n",
    "    print(f\"Processing {weekly_logon_log_path} with {len(df)} rows\")\n",
    "\n",
    "    # Concatenate all DataFrames\n",
    "    logon_csvs = pd.concat([logon_csvs, df], ignore_index=True)\n",
    "\n",
    "print(f\"Total rows in logon_csvs: {len(logon_csvs)}\")\n",
    "\n",
    "#### fix if instant logon and logout ####\n",
    "for i in range(len(logon_csvs)):\n",
    "    if i > 0:\n",
    "        sim_time = logon_csvs.loc[i, 'sim_timestamp']\n",
    "        sim_id = logon_csvs.loc[i, 'id']\n",
    "        prev_id = logon_csvs.loc[i-1, 'id']\n",
    "        if sim_id == prev_id:\n",
    "            prev_sim_time = logon_csvs.loc[i-1, 'sim_timestamp']\n",
    "            if sim_time == prev_sim_time:\n",
    "                # random add near 5 minutes to sim_id\n",
    "                new_time = pd.to_datetime(logon_csvs.loc[i, 'sim_timestamp'], format='%H:%M:%S') + pd.Timedelta(seconds=random.randint(30, 200))\n",
    "                logon_csvs.loc[i, 'sim_timestamp'] = new_time.strftime('%H:%M:%S')\n",
    "\n",
    "starting_date = \"2025-05-01\"\n",
    "\n",
    "#### settle the sim timestamp with proper date ####\n",
    "date_counter = 1\n",
    "for i in range(len(logon_csvs)):\n",
    "    sim_time = pd.to_datetime(logon_csvs.loc[i, 'sim_timestamp'], format='%H:%M:%S')\n",
    "    \n",
    "    if i == 0:\n",
    "        sim_date = starting_date\n",
    "    else:\n",
    "        prev_time = pd.to_datetime(logon_csvs.loc[i-1, 'sim_timestamp'], format='%H:%M:%S')\n",
    "        if (sim_time < prev_time) and ((prev_time - sim_time) > pd.Timedelta(hours=6)):\n",
    "            if date_counter == week_dates[week_pointer]:\n",
    "                # print(\"next week\")\n",
    "                add_date = 8 - week_dates[week_pointer]\n",
    "                week_pointer += 1\n",
    "                date_counter = 1\n",
    "            else:\n",
    "                date_counter += 1\n",
    "                add_date = 1\n",
    "            sim_date = (pd.to_datetime(sim_date) + pd.Timedelta(days=add_date)).strftime('%Y-%m-%d')\n",
    "            # print(f\"Date changed to {sim_date} at index {i}\")\n",
    "    logon_csvs.loc[i, 'full_sim_timestamp'] = f\"{sim_date} {logon_csvs.loc[i, 'sim_timestamp']}\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02a6c991",
   "metadata": {},
   "source": [
    "### Format Fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcbe6268",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = f\"/data2/visitor/ASE25/Chimera/Final-Output/{scenario}/\"\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "sim_idx = logon_csvs.columns.get_loc(\"sim_timestamp\")\n",
    "full_sim = logon_csvs.pop(\"full_sim_timestamp\")\n",
    "logon_csvs.insert(sim_idx + 1, \"full_sim_timestamp\", full_sim)\n",
    "\n",
    "# rename the column \"name\" to \"user\"\n",
    "logon_csvs.rename(columns={'name': 'user'}, inplace=True)\n",
    "# rename the column \"full_sim_timestamp\" to \"time\"\n",
    "logon_csvs.rename(columns={'full_sim_timestamp': 'date'}, inplace=True)\n",
    "# rename the column \"container_id\" to \"pc\"\n",
    "logon_csvs.rename(columns={'container_id': 'pc'}, inplace=True)\n",
    "# rename the column \"status\" to \"activity\"\n",
    "logon_csvs.rename(columns={'status': 'activity'}, inplace=True)\n",
    "\n",
    "# remove the column \"real_timestamp\" and \"sim_timestamp\"\n",
    "logon_csvs.drop(columns=['real_timestamp', 'sim_timestamp'], inplace=True) \n",
    "\n",
    "# sorting by time\n",
    "logon_csvs = logon_csvs.sort_values(by='date', ascending=True).reset_index(drop=True)\n",
    "\n",
    "# save the email_csvs to csv\n",
    "logon_csvs.to_csv(f'{output_dir}/{company_type}-logon.csv', index=False, encoding='utf-8')\n",
    "# logon_csvs.to_csv(f'{output_dir}/{company_type}-logon-full.csv', index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "d2f9ab70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>user</th>\n",
       "      <th>pc</th>\n",
       "      <th>activity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tdev-1</td>\n",
       "      <td>2025-05-01 06:51:26</td>\n",
       "      <td>Ingrid Müller</td>\n",
       "      <td>e61b3c5d78f9</td>\n",
       "      <td>login</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tdev-1</td>\n",
       "      <td>2025-05-01 06:52:35</td>\n",
       "      <td>Ingrid Müller</td>\n",
       "      <td>e61b3c5d78f9</td>\n",
       "      <td>logout</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sdes-1</td>\n",
       "      <td>2025-05-01 07:33:59</td>\n",
       "      <td>Rajan Patel</td>\n",
       "      <td>9b5c6d7e82a3</td>\n",
       "      <td>login</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sdes-2</td>\n",
       "      <td>2025-05-01 07:50:18</td>\n",
       "      <td>Anika Schmidt</td>\n",
       "      <td>c12d3e4f56a7</td>\n",
       "      <td>login</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>uiux-1</td>\n",
       "      <td>2025-05-01 07:51:57</td>\n",
       "      <td>David Chen</td>\n",
       "      <td>9f8e7d6c5b4a</td>\n",
       "      <td>login</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>cart-1</td>\n",
       "      <td>2025-05-01 07:53:22</td>\n",
       "      <td>Leon Moreau</td>\n",
       "      <td>a2b3c4d5e6f7</td>\n",
       "      <td>login</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>sdes-2</td>\n",
       "      <td>2025-05-01 07:53:22</td>\n",
       "      <td>Anika Schmidt</td>\n",
       "      <td>c12d3e4f56a7</td>\n",
       "      <td>logout</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>tart-1</td>\n",
       "      <td>2025-05-01 07:53:31</td>\n",
       "      <td>Ayana Nakamura</td>\n",
       "      <td>5e7f8a9b0c1d</td>\n",
       "      <td>login</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>tart-1</td>\n",
       "      <td>2025-05-01 07:54:28</td>\n",
       "      <td>Ayana Nakamura</td>\n",
       "      <td>5e7f8a9b0c1d</td>\n",
       "      <td>logout</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>cart-1</td>\n",
       "      <td>2025-05-01 07:56:19</td>\n",
       "      <td>Leon Moreau</td>\n",
       "      <td>a2b3c4d5e6f7</td>\n",
       "      <td>logout</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>uiux-1</td>\n",
       "      <td>2025-05-01 07:57:06</td>\n",
       "      <td>David Chen</td>\n",
       "      <td>9f8e7d6c5b4a</td>\n",
       "      <td>logout</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>prod-1</td>\n",
       "      <td>2025-05-01 07:58:30</td>\n",
       "      <td>Olivia Rodriguez</td>\n",
       "      <td>c3d2e1f0a9b8</td>\n",
       "      <td>login</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>cdev-3</td>\n",
       "      <td>2025-05-01 07:59:03</td>\n",
       "      <td>Mei Lin</td>\n",
       "      <td>1c3b9a7f2d4e</td>\n",
       "      <td>login</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>beng-1</td>\n",
       "      <td>2025-05-01 07:59:50</td>\n",
       "      <td>Rajesh Kapoor</td>\n",
       "      <td>2b9c0d1e3a4f</td>\n",
       "      <td>login</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>qtest-1</td>\n",
       "      <td>2025-05-01 08:00:10</td>\n",
       "      <td>Ethan Carter</td>\n",
       "      <td>7b8a9c0d1e2f</td>\n",
       "      <td>login</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>sdev-1</td>\n",
       "      <td>2025-05-01 08:01:11</td>\n",
       "      <td>Carlos Silva</td>\n",
       "      <td>7f4a2b8c9d6e</td>\n",
       "      <td>login</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>ldes-1</td>\n",
       "      <td>2025-05-01 08:02:24</td>\n",
       "      <td>Naomi Walker</td>\n",
       "      <td>f89a4b3c21d0</td>\n",
       "      <td>login</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>aud-1</td>\n",
       "      <td>2025-05-01 08:02:39</td>\n",
       "      <td>Sakura Ishikawa</td>\n",
       "      <td>b9c8a7f6e5d4</td>\n",
       "      <td>login</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>qtest-1</td>\n",
       "      <td>2025-05-01 08:03:30</td>\n",
       "      <td>Ethan Carter</td>\n",
       "      <td>7b8a9c0d1e2f</td>\n",
       "      <td>logout</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>cdev-1</td>\n",
       "      <td>2025-05-01 08:03:37</td>\n",
       "      <td>Aisha Sharma</td>\n",
       "      <td>b759e26d31a5</td>\n",
       "      <td>login</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id                 date              user            pc activity\n",
       "0    tdev-1  2025-05-01 06:51:26     Ingrid Müller  e61b3c5d78f9    login\n",
       "1    tdev-1  2025-05-01 06:52:35     Ingrid Müller  e61b3c5d78f9   logout\n",
       "2    sdes-1  2025-05-01 07:33:59       Rajan Patel  9b5c6d7e82a3    login\n",
       "3    sdes-2  2025-05-01 07:50:18     Anika Schmidt  c12d3e4f56a7    login\n",
       "4    uiux-1  2025-05-01 07:51:57        David Chen  9f8e7d6c5b4a    login\n",
       "5    cart-1  2025-05-01 07:53:22       Leon Moreau  a2b3c4d5e6f7    login\n",
       "6    sdes-2  2025-05-01 07:53:22     Anika Schmidt  c12d3e4f56a7   logout\n",
       "7    tart-1  2025-05-01 07:53:31    Ayana Nakamura  5e7f8a9b0c1d    login\n",
       "8    tart-1  2025-05-01 07:54:28    Ayana Nakamura  5e7f8a9b0c1d   logout\n",
       "9    cart-1  2025-05-01 07:56:19       Leon Moreau  a2b3c4d5e6f7   logout\n",
       "10   uiux-1  2025-05-01 07:57:06        David Chen  9f8e7d6c5b4a   logout\n",
       "11   prod-1  2025-05-01 07:58:30  Olivia Rodriguez  c3d2e1f0a9b8    login\n",
       "12   cdev-3  2025-05-01 07:59:03           Mei Lin  1c3b9a7f2d4e    login\n",
       "13   beng-1  2025-05-01 07:59:50     Rajesh Kapoor  2b9c0d1e3a4f    login\n",
       "14  qtest-1  2025-05-01 08:00:10      Ethan Carter  7b8a9c0d1e2f    login\n",
       "15   sdev-1  2025-05-01 08:01:11      Carlos Silva  7f4a2b8c9d6e    login\n",
       "16   ldes-1  2025-05-01 08:02:24      Naomi Walker  f89a4b3c21d0    login\n",
       "17    aud-1  2025-05-01 08:02:39   Sakura Ishikawa  b9c8a7f6e5d4    login\n",
       "18  qtest-1  2025-05-01 08:03:30      Ethan Carter  7b8a9c0d1e2f   logout\n",
       "19   cdev-1  2025-05-01 08:03:37      Aisha Sharma  b759e26d31a5    login"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logon_csvs.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7147aea3",
   "metadata": {},
   "source": [
    "# Find all keywords in agent actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08b13132",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'shell_exec', 'browse_url', 'search_duckduckgo', 'file_find_in_content', 'write_to_file', 'search_google', 'file_find_by_name'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "import os \n",
    "import pandas as pd\n",
    "import json\n",
    "import ast\n",
    "from tqdm import tqdm\n",
    "\n",
    "# read four dirs email.csv\n",
    "weeks = range(1, 5)\n",
    "week_dates = [5, 5, 5, 5]\n",
    "week_pointer = 0\n",
    "\n",
    "scenario = \"Tech-Company\"\n",
    "company_type_member = \"tech_company\"\n",
    "company_type = \"tech\"\n",
    "\n",
    "\n",
    "# Reading\n",
    "root_dir = f'/data2/visitor/ASE25/Chimera-Dataset/'\n",
    "\n",
    "id_role_map = {}\n",
    "id_list = []\n",
    "profile_list = []\n",
    "\n",
    "#######################\n",
    "profile_output_dir = f\"experiment_output/gemini_{company_type_member}/generated_members\"\n",
    "for file in os.listdir(profile_output_dir):\n",
    "    if file.endswith(\".jsonc\"):\n",
    "        member_profile_path = os.path.join(profile_output_dir, file)\n",
    "        with open(member_profile_path, 'r') as f:\n",
    "            member_profile = json.load(f)\n",
    "        id_role_map[member_profile['id']] = member_profile['role'] # add id-role map\n",
    "        id_list.append(member_profile['id'])\n",
    "        profile_list.append(member_profile) # add profile\n",
    "#######################\n",
    "\n",
    "week = 1\n",
    "member_id = 'cdev-1'\n",
    "\n",
    "function_set = set()\n",
    "\n",
    "for week in weeks:\n",
    "    weekly_dir = os.path.join(root_dir, scenario, f'week{week}-gemini-{company_type}')\n",
    "    execution_log_path = os.path.join(weekly_dir, \"execution_logs\")\n",
    "    \n",
    "    for member_id in id_list:    \n",
    "        user_log_dir = os.path.join(execution_log_path, member_id)\n",
    "\n",
    "        # for every file inside the user_log_dir, read the file and extract the content and do not read the file with \"solution\"\n",
    "        log_files = [f for f in os.listdir(user_log_dir) if f.endswith('.log') and 'solution' not in f]\n",
    "        for member_action_log in tqdm(log_files, desc=f\"Processing logs for {member_id}\"):\n",
    "            member_action_log_path = os.path.join(user_log_dir, member_action_log)\n",
    "            # with open(member_action_log_path, 'r') as f:\n",
    "            # if \"cdev-1_week_1_Friday_executio_task_50\" in member_action_log:\n",
    "            with open(member_action_log_path, 'r') as f:\n",
    "                content = f.readlines()\n",
    "                for line in content:\n",
    "                    if \"'tool_calls': [{'id': 'null', 'type': 'function', 'function': {'name':\" in line:\n",
    "                        # find the word quoted in '' after 'tool_calls': [{'id': 'null', 'type': 'function', 'function': {'name':\n",
    "                        match = re.search(r\"'name': '([^']+)'\", line)\n",
    "                        if match:\n",
    "                            function_name = match.group(1)\n",
    "                            function_set.add(function_name)\n",
    "\n",
    "print(function_set)\n",
    "                    # extract the function name\n",
    "                    # print(line)\n",
    "                # if \"start_url\" in line:\n",
    "                #     # extract all the url from the line, search https://\n",
    "                #     urls = re.findall(r'https?://[^\\s]+', line)\n",
    "                #     # print(urls)\n",
    "                #     # extract the time\n",
    "                #     time = line.split(',')[0].strip()\n",
    "                #     print(f\"Time: {time}\")\n",
    "\n",
    "\n",
    "# 'tool_calls': [{'id': 'null', 'type':\n",
    "# {'shell_exec', 'browse_url', 'search_duckduckgo', 'file_find_in_content', 'write_to_file', 'search_google', 'file_find_by_name'}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f40fa8f",
   "metadata": {},
   "source": [
    "# HTTPS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "6b9aa4db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_url(url):\n",
    "    return url.rstrip('\",\\' >}\\]\\n\\r\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "d5e54473",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                  \r"
     ]
    }
   ],
   "source": [
    "import os \n",
    "import pandas as pd\n",
    "import json\n",
    "import ast\n",
    "from tqdm import tqdm\n",
    "\n",
    "# read four dirs email.csv\n",
    "weeks = range(1, 5)\n",
    "week_dates = [5, 5, 5, 5]\n",
    "week_pointer = 0\n",
    "\n",
    "scenario = \"Tech-Company\"\n",
    "company_type_member = \"tech_company\"\n",
    "company_type = \"tech\"\n",
    "\n",
    "output_dir = f\"/data2/visitor/ASE25/Chimera/Final-Output/{scenario}/\"\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "output_csv = f'{output_dir}/{company_type}-http-raw.csv'\n",
    "\n",
    "# Reading\n",
    "root_dir = f'/data2/visitor/ASE25/Chimera-Dataset/'\n",
    "\n",
    "id_role_map = {}\n",
    "id_list = []\n",
    "profile_list = []\n",
    "\n",
    "#######################\n",
    "profile_output_dir = f\"experiment_output/gemini_{company_type_member}/generated_members\"\n",
    "for file in os.listdir(profile_output_dir):\n",
    "    if file.endswith(\".jsonc\"):\n",
    "        member_profile_path = os.path.join(profile_output_dir, file)\n",
    "        with open(member_profile_path, 'r') as f:\n",
    "            member_profile = json.load(f)\n",
    "        id_role_map[member_profile['id']] = member_profile['role'] # add id-role map\n",
    "        id_list.append(member_profile['id'])\n",
    "        profile_list.append(member_profile) # add profile\n",
    "#######################\n",
    "\n",
    "data_rows = []\n",
    "last_url = None\n",
    "\n",
    "for week in weeks:\n",
    "    weekly_dir = os.path.join(root_dir, scenario, f'week{week}-gemini-{company_type}')\n",
    "    execution_log_path = os.path.join(weekly_dir, \"execution_logs\")\n",
    "    \n",
    "    for member_id in tqdm(id_list, desc=f\"Processing member logs for week {week}\", leave=False):    \n",
    "        user_log_dir = os.path.join(execution_log_path, member_id)\n",
    "\n",
    "        # for every file inside the user_log_dir, read the file and extract the content and do not read the file with \"solution\"\n",
    "        log_files = [f for f in os.listdir(user_log_dir) if f.endswith('.log') and 'solution' not in f]\n",
    "        for member_action_log in tqdm(log_files, desc=f\"Processing logs for {member_id}\", leave=False):\n",
    "            member_action_log_path = os.path.join(user_log_dir, member_action_log)\n",
    "\n",
    "            with open(member_action_log_path, 'r') as f:\n",
    "                content = f.readlines()\n",
    "            for line in content:\n",
    "                if \"'tool_calls': [{'id': 'null', 'type': 'function', 'function': {'name':\" in line:\n",
    "                    match = re.search(r\"'name': '([^']+)'\", line)\n",
    "                    if match:\n",
    "                        function_name = match.group(1)\n",
    "\n",
    "                        # extract the time\n",
    "                        time = line.split(',')[0].strip()\n",
    "                        \n",
    "                        # clean_line = line.encode('utf-8').decode('unicode_escape')\n",
    "                        # get the urls for accessing the function\n",
    "                        urls = re.findall(r'https?://[^\\s]+', line)\n",
    "                        # deduplicate urls\n",
    "                        urls = list(set(urls))\n",
    "                        # print(urls)\n",
    "                        # assert False\n",
    "                        for url in urls:\n",
    "                            # if url contains '}, remove i\n",
    "                            url = url.split(\"\\'}\")[0]\n",
    "                            url = url.split(\"\\')\")[0]\n",
    "                            url = url.split(\"]\")[0]\n",
    "                            url = clean_url(url)\n",
    "                            \n",
    "                            row = {\n",
    "                                'real_timestamp': time,\n",
    "                                'id': member_id,\n",
    "                                'url': url\n",
    "                            }\n",
    "                        # if row url is not equal to the previous row url, append the row\n",
    "                        if url != last_url:\n",
    "                            data_rows.append(row)\n",
    "                            last_url = url\n",
    "\n",
    "df = pd.DataFrame(data_rows)\n",
    "# sort by real_timestamp before saving\n",
    "df['real_timestamp'] = pd.to_datetime(df['real_timestamp'], format='%Y-%m-%d %H:%M:%S')\n",
    "df = df.sort_values(by='real_timestamp', ascending=True).reset_index(drop=True)\n",
    "\n",
    "# check whether previous url is same as current url\n",
    "dupe_mask = (df['url'] == df['url'].shift(1)) & (df['id'] == df['id'].shift(1))\n",
    "df = df[~dupe_mask].reset_index(drop=True)\n",
    "\n",
    "df.to_csv(output_csv, index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "d1bfb44a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import pandas as pd\n",
    "import json\n",
    "import ast\n",
    "import random\n",
    "import requests\n",
    "from tqdm import tqdm\n",
    "\n",
    "# read four dirs email.csv\n",
    "weeks = range(1, 5)\n",
    "week_dates = [5, 5, 5, 5]\n",
    "week_pointer = 0\n",
    "\n",
    "scenario = \"Tech-Company\"\n",
    "company_type_member = \"tech_company\"\n",
    "company_type = \"tech\"\n",
    "\n",
    "output_dir = f\"/data2/visitor/ASE25/Chimera/Final-Output/{scenario}/\"\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "raw_csv = f'{output_dir}/{company_type}-http-raw.csv'\n",
    "\n",
    "# reading the raw csv\n",
    "raw_df = pd.read_csv(raw_csv, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "a635582c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>real_timestamp</th>\n",
       "      <th>id</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2025-05-14 19:29:45</td>\n",
       "      <td>sdes-1</td>\n",
       "      <td>https://www.researchgate.net/publication/38196...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2025-05-14 19:29:53</td>\n",
       "      <td>sdes-1</td>\n",
       "      <td>https://www.sciencedirect.com/journal/games-an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2025-05-14 19:32:28</td>\n",
       "      <td>sdes-1</td>\n",
       "      <td>https://www.economist.com/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2025-05-14 19:32:33</td>\n",
       "      <td>sdes-1</td>\n",
       "      <td>https://www.msn.com/en-us/money/markets/the-ec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2025-05-14 19:32:53</td>\n",
       "      <td>uiux-1</td>\n",
       "      <td>https://architizer.com/blog/inspiration/collec...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        real_timestamp      id  \\\n",
       "0  2025-05-14 19:29:45  sdes-1   \n",
       "1  2025-05-14 19:29:53  sdes-1   \n",
       "2  2025-05-14 19:32:28  sdes-1   \n",
       "3  2025-05-14 19:32:33  sdes-1   \n",
       "4  2025-05-14 19:32:53  uiux-1   \n",
       "\n",
       "                                                 url  \n",
       "0  https://www.researchgate.net/publication/38196...  \n",
       "1  https://www.sciencedirect.com/journal/games-an...  \n",
       "2                         https://www.economist.com/  \n",
       "3  https://www.msn.com/en-us/money/markets/the-ec...  \n",
       "4  https://architizer.com/blog/inspiration/collec...  "
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e53f9a39",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 2669/9421 [38:59<1:20:38,  1.40it/s] "
     ]
    }
   ],
   "source": [
    "# 1. match up with the actual time\n",
    "logon_csv = f'{output_dir}/{company_type}-logon-full.csv'\n",
    "logon_df = pd.read_csv(logon_csv, encoding='utf-8')\n",
    "\n",
    "logon_df['real_timestamp'] = pd.to_datetime(logon_df['real_timestamp'])\n",
    "logon_df['date'] = pd.to_datetime(logon_df['date'])\n",
    "raw_df['real_timestamp'] = pd.to_datetime(raw_df['real_timestamp'])\n",
    "\n",
    "http_dates = []\n",
    "\n",
    "raw_df = raw_df.sort_values('real_timestamp')\n",
    "logon_df = logon_df.sort_values('real_timestamp')\n",
    "\n",
    "result = pd.merge_asof(\n",
    "    raw_df,\n",
    "    logon_df,\n",
    "    on='real_timestamp',\n",
    "    by='id',\n",
    "    direction='nearest'\n",
    ")\n",
    "\n",
    "# 2. mutate the date time by up to 1 minute\n",
    "def mutate_time(dt):\n",
    "    # Randomly add or subtract up to 1 minute\n",
    "    delta = pd.Timedelta(seconds=random.randint(-30, 30))\n",
    "    return dt + delta\n",
    "result['date'] = result['date'].apply(mutate_time)\n",
    "\n",
    "# 3. remove sim_timestamp, real_timestamp, activity\n",
    "result.drop(columns=['sim_timestamp', 'real_timestamp', 'activity'], inplace=True)\n",
    "\n",
    "# 4. sort by date\n",
    "result = result.sort_values(by='date', ascending=True).reset_index(drop=True)\n",
    "\n",
    "# 5. content column\n",
    "def fetch_content(url):\n",
    "    try:\n",
    "        resp = requests.get(url, timeout=10)\n",
    "        resp.raise_for_status()\n",
    "        return resp.text[:5000]  # Limit content to first 1000 characters\n",
    "    except Exception as e:\n",
    "        return f\"Error: {e}\"\n",
    "tqdm.pandas()\n",
    "df['content'] = df['url'].progress_apply(fetch_content)\n",
    "\n",
    "# 6. save to csv\n",
    "output_csv = f'{output_dir}/{company_type}-http.csv'\n",
    "result.to_csv(output_csv, index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9223d949",
   "metadata": {},
   "source": [
    "# Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "850f25d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import pandas as pd\n",
    "import json\n",
    "import ast\n",
    "import re\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import lorem\n",
    "\n",
    "# read four dirs email.csv\n",
    "weeks = range(1, 5)\n",
    "\n",
    "scenario = \"Tech-Company\"\n",
    "company_type_member = \"tech_company\"\n",
    "company_type = \"tech\"\n",
    "\n",
    "output_dir = f\"/data2/visitor/ASE25/Chimera/Final-Output/{scenario}/\"\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "output_csv = f'{output_dir}/{company_type}-file-raw.csv'\n",
    "\n",
    "# Reading\n",
    "root_dir = f'/data2/visitor/ASE25/Chimera-Dataset/'\n",
    "\n",
    "id_role_map = {}\n",
    "id_list = []\n",
    "profile_list = []\n",
    "\n",
    "#######################\n",
    "profile_output_dir = f\"experiment_output/gemini_{company_type_member}/generated_members\"\n",
    "for file in os.listdir(profile_output_dir):\n",
    "    if file.endswith(\".jsonc\"):\n",
    "        member_profile_path = os.path.join(profile_output_dir, file)\n",
    "        with open(member_profile_path, 'r') as f:\n",
    "            member_profile = json.load(f)\n",
    "        id_role_map[member_profile['id']] = member_profile['role'] # add id-role map\n",
    "        id_list.append(member_profile['id'])\n",
    "        profile_list.append(member_profile) # add profile\n",
    "#######################\n",
    "\n",
    "data_rows = []\n",
    "last_url = None\n",
    "\n",
    "for week in weeks:\n",
    "    weekly_dir = os.path.join(root_dir, scenario, f'week{week}-gemini-{company_type}')\n",
    "    execution_log_path = os.path.join(weekly_dir, \"execution_logs\")\n",
    "    \n",
    "    for member_id in tqdm(id_list, desc=f\"Processing member logs for week {week}\", leave=False):    \n",
    "        user_log_dir = os.path.join(execution_log_path, member_id)\n",
    "\n",
    "        # for every file inside the user_log_dir, read the file and extract the content and do not read the file with \"solution\"\n",
    "        log_files = [f for f in os.listdir(user_log_dir) if f.endswith('.log') and 'solution' not in f]\n",
    "        for member_action_log in tqdm(log_files, desc=f\"Processing logs for {member_id}\", leave=False):\n",
    "            member_action_log_path = os.path.join(user_log_dir, member_action_log)\n",
    "\n",
    "            with open(member_action_log_path, 'r') as f:\n",
    "                content = f.readlines()\n",
    "            for line in content:\n",
    "                if \"'tool_calls': [{'id': 'null', 'type': 'function', 'function': {'name':\" in line:\n",
    "                    match = re.search(r\"'name': '([^']+)'\", line)\n",
    "\n",
    "                    time = line.split(',')[0].strip()\n",
    "                    if match:\n",
    "                        function_name = match.group(1)\n",
    "                        # 'tool_calls': [{'id': 'null', 'type':\n",
    "                        # {'shell_exec', 'browse_url', 'search_duckduckgo', 'file_find_in_content', 'write_to_file', 'search_google', 'file_find_by_name'}\n",
    "                        if function_name == 'shell_exec':\n",
    "                            match = re.search(r'\"command\"\\s*:\\s*\"([^\"]+)\"', line)\n",
    "                            if match:\n",
    "                                command_data = match.group(1)\n",
    "                                # pass\n",
    "\n",
    "                        elif function_name == 'file_find_in_content':\n",
    "                            match = re.search(r\"'arguments':\\s*'\\{\\\"file\\\":\\s*\\\"([^\\\"]+)\\\"\", line)\n",
    "                            if match:\n",
    "                                file_read = match.group(1)\n",
    "                                row = {\n",
    "                                    'real_timestamp': time,\n",
    "                                    'id': member_id,\n",
    "                                    'filename': file_read,\n",
    "                                    'type': 'read',\n",
    "                                    'content': lorem.sentence()\n",
    "                                }\n",
    "                            data_rows.append(row)\n",
    "                        \n",
    "                        elif function_name == 'file_find_by_name':\n",
    "                            matches = re.findall(r\"'arguments':\\s*'\\{\\\"glob\\\":\\s*\\\"([^\\\"]+)\\\"\", line)\n",
    "                            for match in matches:\n",
    "                                file_name = match\n",
    "                                row = {\n",
    "                                    'real_timestamp': time,\n",
    "                                    'id': member_id,\n",
    "                                    'filename': file_name,\n",
    "                                    'type': 'read',\n",
    "                                    'content': lorem.sentence()\n",
    "                                }\n",
    "                                data_rows.append(row)\n",
    "                        \n",
    "                        elif function_name == 'write_to_file':\n",
    "                            content_match = re.search(r\"'arguments':\\s*'\\{\\\"content\\\":\\s*\\\"([^\\\"]+)\\\"\", line)\n",
    "                            filename_match = re.search(r'\"filename\"\\s*:\\s*\"([^\"]+)\"', line)\n",
    "\n",
    "                            row = {\n",
    "                                'real_timestamp': time,\n",
    "                                'id': member_id,\n",
    "                                'filename': filename_match.group(1),\n",
    "                                'type': 'write',\n",
    "                                'content': content_match.group(1) if content_match else lorem.sentence()\n",
    "                            }\n",
    "                            data_rows.append(row)\n",
    "                \n",
    "                if \"Content successfully written to file\" in line:\n",
    "                    match = re.search(r\"'content': 'Content successfully written to file: ([^']+)'\", line)\n",
    "                    if match:\n",
    "                        file_written = match.group(1)\n",
    "                        row = {\n",
    "                            'real_timestamp': time,\n",
    "                            'id': member_id,\n",
    "                            'filename': file_written,\n",
    "                            'type': 'write',\n",
    "                            'content': lorem.sentence()\n",
    "                        }\n",
    "                        data_rows.append(row)\n",
    "\n",
    "df = pd.DataFrame(data_rows)\n",
    "\n",
    "df.to_csv(output_csv, index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89545ace",
   "metadata": {},
   "source": [
    "### Postprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "3e3c4bc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import pandas as pd\n",
    "import json\n",
    "import ast\n",
    "import re\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import lorem\n",
    "import random\n",
    "\n",
    "# read four dirs email.csv\n",
    "weeks = range(1, 5)\n",
    "\n",
    "scenario = \"Tech-Company\"\n",
    "company_type_member = \"tech_company\"\n",
    "company_type = \"tech\"\n",
    "\n",
    "output_dir = f\"/data2/visitor/ASE25/Chimera/Final-Output/{scenario}/\"\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "output_csv = f'{output_dir}/{company_type}-file-raw.csv'\n",
    "\n",
    "# Reading\n",
    "root_dir = f'/data2/visitor/ASE25/Chimera-Dataset/'\n",
    "\n",
    "raw_csv = f'{output_dir}/{company_type}-file-raw.csv'\n",
    "\n",
    "# reading the raw csv\n",
    "raw_df = pd.read_csv(raw_csv, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "93f15e5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>real_timestamp</th>\n",
       "      <th>id</th>\n",
       "      <th>filename</th>\n",
       "      <th>type</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2025-05-15 18:37:47</td>\n",
       "      <td>cart-1</td>\n",
       "      <td>character_color_rendering_backup.txt</td>\n",
       "      <td>write</td>\n",
       "      <td>Conversation history and task plan regarding c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2025-05-15 18:37:47</td>\n",
       "      <td>cart-1</td>\n",
       "      <td>/data/Chimera/demo/execution_logs/cart-1...</td>\n",
       "      <td>write</td>\n",
       "      <td>Quiquia tempora amet dolorem.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2025-05-15 18:37:51</td>\n",
       "      <td>cart-1</td>\n",
       "      <td>character_color_rendering_backup.txt</td>\n",
       "      <td>write</td>\n",
       "      <td>Conversation history and task plan regarding c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2025-05-15 18:37:51</td>\n",
       "      <td>cart-1</td>\n",
       "      <td>/data/Chimera/demo/execution_logs/cart-1...</td>\n",
       "      <td>write</td>\n",
       "      <td>Quisquam non non adipisci aliquam etincidunt v...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2025-05-15 18:37:58</td>\n",
       "      <td>cart-1</td>\n",
       "      <td>character_color_rendering_backup.txt</td>\n",
       "      <td>write</td>\n",
       "      <td>Conversation history and task plan regarding c...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        real_timestamp      id  \\\n",
       "0  2025-05-15 18:37:47  cart-1   \n",
       "1  2025-05-15 18:37:47  cart-1   \n",
       "2  2025-05-15 18:37:51  cart-1   \n",
       "3  2025-05-15 18:37:51  cart-1   \n",
       "4  2025-05-15 18:37:58  cart-1   \n",
       "\n",
       "                                            filename   type  \\\n",
       "0               character_color_rendering_backup.txt  write   \n",
       "1  /data/Chimera/demo/execution_logs/cart-1...  write   \n",
       "2               character_color_rendering_backup.txt  write   \n",
       "3  /data/Chimera/demo/execution_logs/cart-1...  write   \n",
       "4               character_color_rendering_backup.txt  write   \n",
       "\n",
       "                                             content  \n",
       "0  Conversation history and task plan regarding c...  \n",
       "1                      Quiquia tempora amet dolorem.  \n",
       "2  Conversation history and task plan regarding c...  \n",
       "3  Quisquam non non adipisci aliquam etincidunt v...  \n",
       "4  Conversation history and task plan regarding c...  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sort based on real_timestamp\n",
    "# raw_df['real_timestamp'] = pd.to_datetime(raw_df['real_timestamp'])\n",
    "# raw_df = raw_df.sort_values('real_timestamp').reset_index(drop=True)\n",
    "raw_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df283ad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. match up with the actual time\n",
    "logon_csv = f'{output_dir}/{company_type}-logon-full.csv'\n",
    "logon_df = pd.read_csv(logon_csv, encoding='utf-8')\n",
    "\n",
    "logon_df['real_timestamp'] = pd.to_datetime(logon_df['real_timestamp'])\n",
    "logon_df['date'] = pd.to_datetime(logon_df['date'])\n",
    "raw_df['real_timestamp'] = pd.to_datetime(raw_df['real_timestamp'])\n",
    "\n",
    "raw_df = raw_df.sort_values('real_timestamp')\n",
    "logon_df = logon_df.sort_values('real_timestamp')\n",
    "\n",
    "result = pd.merge_asof(\n",
    "    raw_df,\n",
    "    logon_df,\n",
    "    on='real_timestamp',\n",
    "    by='id',\n",
    "    direction='nearest'\n",
    ")\n",
    "\n",
    "# # 2. mutate the date time by up to 1 minute\n",
    "def mutate_time(dt):\n",
    "    # Randomly add or subtract up to 1 minute\n",
    "    delta = pd.Timedelta(seconds=random.randint(-10, 10))\n",
    "    return dt + delta\n",
    "result['date'] = result['date'].apply(mutate_time)\n",
    "\n",
    "# # 3. remove sim_timestamp, real_timestamp, activity\n",
    "result.drop(columns=['sim_timestamp', 'real_timestamp', 'activity'], inplace=True)\n",
    "\n",
    "# # 4. sort by date\n",
    "result = result.sort_values(by='date', ascending=True).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "d447dc2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "result.head(5)\n",
    "# 5. save to csv\n",
    "output_csv = f'{output_dir}/{company_type}-file.csv'\n",
    "result.to_csv(output_csv, index=False, encoding='utf-8')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "shift",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
